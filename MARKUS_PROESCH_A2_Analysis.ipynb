{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2: Classification Modeling Case Study\n",
    "## Apprentice Chef - Machine Learning\n",
    "\n",
    "Student: Markus Proesch\n",
    "Cohort: 4\n",
    "Hult International Business School\n",
    "\n",
    "Deliverables: \n",
    "- Analysis of Apprentice Chef's customers user data.\n",
    "- Build insight about the Halfway There promotion, offering customers over 21 1/2 bottle of CA wine.\n",
    "- Build a model to predict cross sell success.\n",
    "\n",
    "This assignment encompasses feature engineering, variable selection, and model development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the following packages to run the script and get the right output.\n",
    "\n",
    "Exploring the dataset, classes and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                      # data science essentials\n",
    "import matplotlib.pyplot as plt                          # data visualization\n",
    "import seaborn as sns                                    # enhanced data visualization\n",
    "import statsmodels.formula.api as smf                    # explanatory model \n",
    "from sklearn.model_selection import train_test_split     # divides dataset into a train and test set\n",
    "from sklearn.linear_model import LogisticRegression      # Logistic Regression\n",
    "from sklearn.metrics import confusion_matrix             # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score                # Calculating the ROC and AUC\n",
    "from sklearn.neighbors import KNeighborsClassifier       # KNN for classification\n",
    "from sklearn.preprocessing import StandardScaler         # Standardizing values\n",
    "from sklearn.tree import DecisionTreeClassifier          # classification trees\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # Gradient Booster for classification\n",
    "from sklearn.ensemble import RandomForestClassifier      # Random Forest for classification   \n",
    "from sklearn.model_selection import GridSearchCV         # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer                  # customizable scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file \n",
    "original_df  = pd.read_excel('Apprentice Chef Dataset.xlsx')\n",
    "\n",
    "# Explore the data and struckture + columns\n",
    "#original_df.info()\n",
    "#original_df.describe()\n",
    "\n",
    "# Exploring the original variables in the dataset\n",
    "#original_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering:\n",
    "Developing different features that will be used later in the analysis. \n",
    "\n",
    "- AVG_PRICE_PER_MEAL is the average price a customer paid per meal they ordered. Including the Weekly Plan  subscription.\n",
    "\n",
    "- Missing values in FAMILY_NAME were flagged, but after analyzing the dataset further. Approximately 1/4 of the NAMES were equal to FAMILY_NAME so missing values in FAMILY_NAME were filled with same value as in NAME.\n",
    "\n",
    "- The emails are divided into subgroups based on their domain. The different domain groups are:\n",
    "\n",
    "Professional: \n",
    "@mmm.com, @amex.com, @apple.com, @boeing.com, @caterpillar.com, @chevron.com, @cisco.com, @cocacola.com\n",
    "@disney.com, @dupont.com, @exxon.com, @ge.org, @goldmansacs.com, @homedepot.com, @ibm.com, @intel.com\n",
    "@jnj.com, @jpmorgan.com, @mcdonalds.com, @merck.com, @microsoft.com, @nike.com, @pfizer.com, @pg.com, @travelers.com\n",
    "@unitedtech.com, @unitedhealth.com, @verizon.com, @visa.com, @walmart.com\n",
    "\n",
    "Personal: \n",
    "@gmail.com, @yahoo.com, @protonmail.com\n",
    "\n",
    "Junk: \n",
    "@me.com, @aol.com, @hotmail.com, @live.com, @msn.com, @passport.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Avg. Price per Meal variable\n",
    "original_df['AVG_PRICE_PER_MEAL'] = original_df['REVENUE']/original_df['TOTAL_MEALS_ORDERED']\n",
    "\n",
    "\n",
    "# Flagging all observations/customers with no input in Family Name\n",
    "for col in original_df:\n",
    "\n",
    "        if original_df[col].isnull().astype(int).sum() > 0:\n",
    "            original_df['mv_'+col] = original_df[col].isnull().astype(int)\n",
    "\n",
    "# Filled NA in FAMILY_NAME with same name as in FIRST_NAME since that seems to be the way to do it\n",
    "original_df['FAMILY_NAME'] = original_df['FAMILY_NAME'].fillna(original_df['FIRST_NAME'])\n",
    "\n",
    "# Drop the flagged missing values in FAMILY_NAME as they are replaced with FIRST_NAME\n",
    "original_df = original_df.drop(columns = 'mv_FAMILY_NAME')            \n",
    "            \n",
    "\n",
    "# Dummie variables from the email domain.\n",
    "# Dataset has to be a DataFrame for .iterrows() to work\n",
    "original_df_email       = pd.DataFrame(original_df['EMAIL'])\n",
    "\n",
    "placeholder_lst  = []\n",
    "\n",
    "for index, col in original_df_email.iterrows():\n",
    "    split_email  = original_df_email.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "email_df         = pd.DataFrame(placeholder_lst)\n",
    "email_df.columns = ['name', 'domain']\n",
    "\n",
    "# Domain groups\n",
    "personal_domain     = ['@gmail.com', '@yahoo.com','@protonmail.com']\n",
    "professional_domain = ['@mmm.com', '@amex.com','@apple.com',\n",
    "                      '@boeing.com','@caterpillar.com',\n",
    "                      '@chevron.com','@cisco.com','@cocacola.com',\n",
    "                      '@disney.com','@dupont.com','@exxon.com',\n",
    "                      '@ge.org','@goldmansacs.com','@homedepot.com',\n",
    "                      '@ibm.com','@intel.com','@jnj.com',\n",
    "                      '@jpmorgan.com','@mcdonalds.com','@merck.com',\n",
    "                      '@microsoft.com','@nike.com','@pfizer.com',\n",
    "                      '@pg.com','@travelers.com','@unitedtech.com',\n",
    "                      '@unitedhealth.com','@verizon.com','@visa.com',\n",
    "                      '@walmart.com']\n",
    "junk_domain         = ['@me.com', '@aol.com', '@hotmail.com', '@live.com',\n",
    "                       '@msn.com','@passport.com']\n",
    "\n",
    "# For loop categorising the different email domains\n",
    "placeholder_lst = []\n",
    "\n",
    "for domain in email_df['domain']:\n",
    "    \n",
    "    if '@' + domain in personal_domain:\n",
    "        placeholder_lst.append('PERSONAL_DOMAIN')\n",
    "    elif '@' + domain in professional_domain:\n",
    "        placeholder_lst.append('PROFESSIONAL_DOMAIN')\n",
    "    else:\n",
    "        placeholder_lst.append('JUNK_DOMAIN')\n",
    "        \n",
    "# make the columns into a series to append it to original dataset        \n",
    "email_df['DOMAIN_GROUP'] = pd.Series(placeholder_lst)\n",
    "\n",
    "# Add the domain categories column to the original dataset \n",
    "original_df['DOMAIN'] = email_df['DOMAIN_GROUP']\n",
    "\n",
    "# Get dummies from the domain variable and drop the original column\n",
    "one_hot_DOMAIN = pd.get_dummies(original_df['DOMAIN'])\n",
    "\n",
    "# Remove the old and add the 3 new columns\n",
    "original_df           = original_df.drop('DOMAIN', axis = 1)\n",
    "original_df           = original_df.join([one_hot_DOMAIN])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NUMBER_NAMES is a count of how many names a customer has in his/her NAME\n",
    "\n",
    "- SAME_NAME is a binary feature showing 1 if the customer has the same FIRST and LAST name, and 0 if they are different.\n",
    "\n",
    "- ATTENDED_MASTER_CLASS is a feature developed from MASTER_CLASS_ATTENDED. Instead of counting the number of classes a customer attended. It is a binary feature where 1 = Attended 1 or more classes, and 0 = Never attended a class\n",
    "\n",
    "- NOBLE is a binary feature where 1 = A person part of the Noble class, and 0 = Not Noble\n",
    "        Who is in the noble class: \n",
    "        _\"zo\", \"mo\" and \"Mo\" is from a foreign language, meaning \"of\"\n",
    "        _\"of\" is often a part of \"Daughter of ..\" or \"Son of ..\"\n",
    "        _\"Lord\" and \"knight\" are also a part of the noble class\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding variable, counting the number of names in NAME column\n",
    "\n",
    "def text_split_feature(col, df, sep=' ', new_col_name=None):\n",
    "    \"\"\"\n",
    "Splits values in a string Series (as part of a DataFrame) and sums the number\n",
    "of resulting items. Automatically appends summed column to original DataFrame.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "col          : column to split\n",
    "df           : DataFrame where column is located\n",
    "sep          : string sequence to split by, default ' '\n",
    "new_col_name : name of new column after summing split, default\n",
    "               'number_of_names'\n",
    "\"\"\"\n",
    "    \n",
    "    original_df[new_col_name] = 0\n",
    "    \n",
    "    \n",
    "    for index, val in original_df.iterrows():\n",
    "        original_df.loc[index, new_col_name] = len(original_df.loc[index, col].split(sep = ' '))\n",
    "        \n",
    "text_split_feature(col = 'NAME', df = original_df, new_col_name = 'NUMBER_NAMES' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding variable where FIRST NAME is the same as FAMILY NAME\n",
    "placeholder_lst = []\n",
    "\n",
    "for row,col in original_df.iterrows():\n",
    "    if original_df.loc[row,'FIRST_NAME'] == original_df.loc[row,'FAMILY_NAME']:\n",
    "        placeholder_lst.append(1)\n",
    "    else:\n",
    "        placeholder_lst.append(0)\n",
    "\n",
    "# Adding the new variable to the original dataset\n",
    "original_df['SAME_NAME'] = pd.Series(placeholder_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making attending a master class into a binary variable\n",
    "placeholder_lst = []\n",
    "\n",
    "for row,col in original_df.iterrows():\n",
    "    if original_df.loc[row,'MASTER_CLASSES_ATTENDED'] >= 1:\n",
    "        placeholder_lst.append(1)\n",
    "    else:\n",
    "        placeholder_lst.append(0)\n",
    "\n",
    "# Adding the new variable to the original dataset\n",
    "original_df['ATTENDED_MASTER_CLASS'] = pd.Series(placeholder_lst)\n",
    "original_df = original_df.drop(columns = 'MASTER_CLASSES_ATTENDED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Flagging NOBLE people in the customer list\n",
    "placeholder_lst = []\n",
    "\n",
    "for row,pattern in original_df.iterrows():\n",
    "    if ' of ' in original_df.loc[row,'NAME'] or \\\n",
    "    'lord' in original_df.loc[row,'NAME'] or \\\n",
    "    'Lord' in original_df.loc[row,'NAME'] or \\\n",
    "    ' mo ' in original_df.loc[row,'NAME'] or \\\n",
    "    ' zo ' in original_df.loc[row,'NAME'] or \\\n",
    "    ' Mo ' in original_df.loc[row,'NAME'] or \\\n",
    "    'Knight' in original_df.loc[row, 'NAME'] or \\\n",
    "    'knight'in original_df.loc[row, 'NAME']:\n",
    "        placeholder_lst.append(1)\n",
    "    else:\n",
    "        placeholder_lst.append(0)\n",
    "\n",
    "original_df['NOBLE'] = pd.Series(placeholder_lst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration: Outliers and thresholds\n",
    "\n",
    "Two for loops used to present all variables with a histogram (frequency) and scatter (relationship) plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df_no_char = original_df.drop(columns = ['NAME', 'EMAIL', 'FIRST_NAME', 'FAMILY_NAME'])\n",
    "\n",
    "#for col in original_df_no_char:\n",
    "    \n",
    "#    fig, ax = plt.subplots(figsize = (10, 8))\n",
    "    \n",
    "#    plt.hist(original_df_no_char[col], bins = 100)\n",
    "#    xlabel = print(f'{col}')\n",
    "#    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df_num = original_df.drop(columns = ['NAME', 'EMAIL', 'FIRST_NAME', 'FAMILY_NAME'])\n",
    "\n",
    "\n",
    "#for col in original_df_num:\n",
    "    \n",
    "#    fig, ax = plt.subplots(figsize = (8, 6))\n",
    "    \n",
    "#    plt.scatter(x = original_df_num[col], y = 'CROSS_SELL_SUCCESS',\n",
    "#                data = original_df_num, alpha = 0.6)\n",
    "#    xlabel = print(f'{col}')\n",
    "#    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers thresholds determined based on the histograms and scatterplots\n",
    "revenue_hi                    = 6500\n",
    "total_meals_hi                = 320\n",
    "unique_meals_hi               = 12\n",
    "contact_w_customer_service_hi = 12\n",
    "avg_time_per_site_hi          = 400\n",
    "cancel_before_noon_hi         = 7\n",
    "late_deliveries_hi            = 15\n",
    "avg_prep_video_hi             = 350\n",
    "total_photoes_hi              = 900\n",
    "avg_meal_price                = 120\n",
    "follow_rec_pct_hi             = 30\n",
    "follow_rec_pct_lo             = 1\n",
    "\n",
    "# FOLLOWED_RECOMMENDATIONS_PCT\n",
    "original_df['out_FOLLOWED_RECOMMENDATIONS_PCT']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_FOLLOWED_RECOMMENDATIONS_PCT'][original_df['FOLLOWED_RECOMMENDATIONS_PCT'] \n",
    "                                                                      > follow_rec_pct_hi]\n",
    "condition_lo = original_df.loc[0:,'out_FOLLOWED_RECOMMENDATIONS_PCT'][original_df['FOLLOWED_RECOMMENDATIONS_PCT'] \n",
    "                                                                      < follow_rec_pct_lo]\n",
    "\n",
    "\n",
    "original_df['out_FOLLOWED_RECOMMENDATIONS_PCT'].replace(to_replace = condition_hi,\n",
    "                                                        value      = 1,\n",
    "                                                        inplace    = True)\n",
    "original_df['out_FOLLOWED_RECOMMENDATIONS_PCT'].replace(to_replace = condition_lo,\n",
    "                                                        value      = 1,\n",
    "                                                        inplace    = True)\n",
    "\n",
    "# REVENUE\n",
    "original_df['out_REVENUE']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_REVENUE'][original_df['REVENUE'] \n",
    "                                                          > revenue_hi]\n",
    "\n",
    "original_df['out_REVENUE'].replace(to_replace = condition_hi,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "# TOTAL_MEALS_ORDERED\n",
    "original_df['out_TOTAL_MEALS_ORDERED']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_TOTAL_MEALS_ORDERED'][original_df['TOTAL_MEALS_ORDERED'] \n",
    "                                                             > total_meals_hi]\n",
    "\n",
    "original_df['out_TOTAL_MEALS_ORDERED'].replace(to_replace = condition_hi,\n",
    "                                               value      = 1,\n",
    "                                               inplace    = True)\n",
    "\n",
    "# UNIQUE_MEALS_PURCH\n",
    "original_df['out_UNIQUE_MEALS_PURCH']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_UNIQUE_MEALS_PURCH'][original_df['UNIQUE_MEALS_PURCH'] \n",
    "                                                            > unique_meals_hi]\n",
    "\n",
    "original_df['out_UNIQUE_MEALS_PURCH'].replace(to_replace = condition_hi,\n",
    "                                              value      = 1,\n",
    "                                              inplace    = True)\n",
    "\n",
    "# CONTACTS_W_CUSTOMER_SERVICE\n",
    "original_df['out_CONTACTS_W_CUSTOMER_SERVICE']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_CONTACTS_W_CUSTOMER_SERVICE'][original_df['CONTACTS_W_CUSTOMER_SERVICE'] \n",
    "                                                                     > contact_w_customer_service_hi]\n",
    "\n",
    "original_df['out_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_hi,\n",
    "                                                       value      = 1,\n",
    "                                                       inplace    = True)\n",
    "\n",
    "# AVG_TIME_PER_SITE_VISIT\n",
    "original_df['out_AVG_TIME_PER_SITE_VISIT']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_AVG_TIME_PER_SITE_VISIT'][original_df['AVG_TIME_PER_SITE_VISIT'] \n",
    "                                                                 > avg_time_per_site_hi]\n",
    "\n",
    "original_df['out_AVG_TIME_PER_SITE_VISIT'].replace(to_replace = condition_hi,\n",
    "                                                   value      = 1,\n",
    "                                                   inplace    = True)\n",
    "\n",
    "# CANCELLATIONS_BEFORE_NOON\n",
    "original_df['out_CANCELLATIONS_BEFORE_NOON']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_CANCELLATIONS_BEFORE_NOON'][original_df['CANCELLATIONS_BEFORE_NOON'] \n",
    "                                                                   > cancel_before_noon_hi]\n",
    "\n",
    "original_df['out_CANCELLATIONS_BEFORE_NOON'].replace(to_replace = condition_hi,\n",
    "                                                     value      = 1,\n",
    "                                                     inplace    = True)\n",
    "\n",
    "# LATE_DELIVERIES\n",
    "original_df['out_LATE_DELIVERIES']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_LATE_DELIVERIES'][original_df['LATE_DELIVERIES'] \n",
    "                                                         > late_deliveries_hi]\n",
    "\n",
    "original_df['out_LATE_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                           value      = 1,\n",
    "                                           inplace    = True)\n",
    "\n",
    "# AVG_PREP_VID_TIME\n",
    "original_df['out_AVG_PREP_VID_TIME']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_AVG_PREP_VID_TIME'][original_df['AVG_PREP_VID_TIME'] \n",
    "                                                          > avg_prep_video_hi]\n",
    "\n",
    "original_df['out_AVG_PREP_VID_TIME'].replace(to_replace = condition_hi,\n",
    "                                             value      = 1,\n",
    "                                             inplace    = True)\n",
    "\n",
    "# TOTAL_PHOTOS_VIEWED\n",
    "original_df['out_TOTAL_PHOTOS_VIEWED']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_TOTAL_PHOTOS_VIEWED'][original_df['TOTAL_PHOTOS_VIEWED'] \n",
    "                                                          > total_photoes_hi]\n",
    "\n",
    "original_df['out_TOTAL_PHOTOS_VIEWED'].replace(to_replace = condition_hi,\n",
    "                                               value      = 1,\n",
    "                                               inplace    = True)\n",
    "\n",
    "# AVG_PRICE_PER_MEAL\n",
    "original_df['out_AVG_PRICE_PER_MEAL']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_AVG_PRICE_PER_MEAL'][original_df['AVG_PRICE_PER_MEAL'] \n",
    "                                                          > avg_meal_price]\n",
    "\n",
    "original_df['out_AVG_PRICE_PER_MEAL'].replace(to_replace = condition_hi,\n",
    "                                              value      = 1,\n",
    "                                              inplace    = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correlation chart with variables correlation with REVENUE\n",
    "# Correlation insight were key to find the 2 important insight\n",
    "#original_df_corr = original_df.corr().round(2)\n",
    "\n",
    "# Heatmap gave a good overview over correlation within the dataset\n",
    "#fig, ax = plt.subplots(figsize  = (20,20))\n",
    "\n",
    "#sns.heatmap(original_df_corr, cmap = 'coolwarm',\n",
    "#            square = True, annot = True,\n",
    "#            linecolor = 'black', linewidths = 0.5)\n",
    "\n",
    "# Looking at correlation with CROSS_SELL_SUCCESS\n",
    "#print(original_df_corr['CROSS_SELL_SUCCESS'].sort_values(ascending=False))\n",
    "\n",
    "# Finding correlation for FOLLOWED_RECOMMENDATIONS_PCT triggering the insight\n",
    "#print(original_df_corr['FOLLOWED_RECOMMENDATIONS_PCT'].sort_values(ascending=False))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into a train and test set for the statsmodel\n",
    "\n",
    "original_df_data   = original_df.drop(columns = 'CROSS_SELL_SUCCESS')\n",
    "\n",
    "original_df_target = original_df.loc[:,'CROSS_SELL_SUCCESS']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(original_df_data,\n",
    "                                                   original_df_target,\n",
    "                                                   test_size = 0.25,\n",
    "                                                   random_state = 222,\n",
    "                                                   stratify = original_df_target)\n",
    "\n",
    "# merging training data for statsmodels since it doesn't work the same way as sci-kit learn\n",
    "chef_train = pd.concat([X_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable selection\n",
    "\n",
    "The p-value threshold at 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "#logistic_initial = smf.logit(formula   = \"\"\"CROSS_SELL_SUCCESS ~ \n",
    "#                             FOLLOWED_RECOMMENDATIONS_PCT\"\"\",\n",
    "#                             data = chef_train)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "#results_logistic = logistic_initial.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "#results_logistic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to print the numeric variable in the right format for statsmodel\n",
    "#for col in original_df:\n",
    "#    print(f\"{col} +\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VARIABLES REMOVED:\n",
    "'TOTAL_MEALS_ORDERED','UNIQUE_MEALS_PURCH', 'CONTACTS_W_CUSTOMER_SERVICE', 'PRODUCT_CATEGORIES_VIEWED', 'AVG_TIME_PER_SITE_VISIT', 'TASTES_AND_PREFERENCES', 'MOBILE_LOGINS', 'PC_LOGINS', 'PACKAGE_LOCKER', 'REFRIGERATED_LOCKER','AVG_PREP_VID_TIME', 'LARGEST_ORDER_SIZE', 'MEDIAN_MEAL_RATING', 'TOTAL_PHOTOS_VIEWED', \n",
    "'AVG_PRICE_PER_MEAL', 'WEEKLY_PLAN','out_REVENUE', 'out_TOTAL_MEALS_ORDERED', 'out_UNIQUE_MEALS_PURCH', 'out_CONTACTS_W_CUSTOMER_SERVICE', 'out_AVG_TIME_PER_SITE_VISIT', 'out_CANCELLATIONS_BEFORE_NOON',\n",
    "'out_LATE_DELIVERIES', 'out_AVG_PREP_VID_TIME', 'out_TOTAL_PHOTOS_VIEWED', 'out_AVG_PRICE_PER_MEAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.353202\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>CROSS_SELL_SUCCESS</td> <th>  No. Observations:  </th>   <td>  1459</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>       <th>  Df Residuals:      </th>   <td>  1442</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>   <td>    16</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 05 Feb 2020</td>  <th>  Pseudo R-squ.:     </th>   <td>0.4375</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:58:29</td>      <th>  Log-Likelihood:    </th>  <td> -515.32</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th>  <td> -916.19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>2.691e-160</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                    <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                        <td>   -1.1058</td> <td>    0.824</td> <td>   -1.342</td> <td> 0.180</td> <td>   -2.720</td> <td>    0.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REVENUE</th>                          <td>   -0.0002</td> <td> 9.28e-05</td> <td>   -1.771</td> <td> 0.077</td> <td>   -0.000</td> <td> 1.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_NUMBER</th>                    <td>    0.8683</td> <td>    0.232</td> <td>    3.744</td> <td> 0.000</td> <td>    0.414</td> <td>    1.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_BEFORE_NOON</th>        <td>    0.2472</td> <td>    0.053</td> <td>    4.632</td> <td> 0.000</td> <td>    0.143</td> <td>    0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_AFTER_NOON</th>         <td>   -0.2809</td> <td>    0.175</td> <td>   -1.602</td> <td> 0.109</td> <td>   -0.624</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EARLY_DELIVERIES</th>                 <td>    0.0628</td> <td>    0.035</td> <td>    1.795</td> <td> 0.073</td> <td>   -0.006</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LATE_DELIVERIES</th>                  <td>    0.0571</td> <td>    0.029</td> <td>    1.952</td> <td> 0.051</td> <td>   -0.000</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FOLLOWED_RECOMMENDATIONS_PCT</th>     <td>    0.0451</td> <td>    0.006</td> <td>    7.640</td> <td> 0.000</td> <td>    0.034</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AVG_CLICKS_PER_VISIT</th>             <td>   -0.1109</td> <td>    0.040</td> <td>   -2.773</td> <td> 0.006</td> <td>   -0.189</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>JUNK_DOMAIN</th>                      <td>   -1.2095</td> <td>    0.206</td> <td>   -5.863</td> <td> 0.000</td> <td>   -1.614</td> <td>   -0.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PROFESSIONAL_DOMAIN</th>              <td>    0.7882</td> <td>    0.179</td> <td>    4.403</td> <td> 0.000</td> <td>    0.437</td> <td>    1.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NUMBER_NAMES</th>                     <td>    0.4757</td> <td>    0.217</td> <td>    2.192</td> <td> 0.028</td> <td>    0.050</td> <td>    0.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SAME_NAME</th>                        <td>   -0.9284</td> <td>    0.265</td> <td>   -3.505</td> <td> 0.000</td> <td>   -1.448</td> <td>   -0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ATTENDED_MASTER_CLASS</th>            <td>    0.2648</td> <td>    0.175</td> <td>    1.512</td> <td> 0.131</td> <td>   -0.079</td> <td>    0.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOBLE</th>                            <td>   -1.7068</td> <td>    0.590</td> <td>   -2.893</td> <td> 0.004</td> <td>   -2.863</td> <td>   -0.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_FOLLOWED_RECOMMENDATIONS_PCT</th> <td>    2.4356</td> <td>    0.219</td> <td>   11.126</td> <td> 0.000</td> <td>    2.007</td> <td>    2.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>out_LATE_DELIVERIES</th>              <td>   -3.0353</td> <td>    2.115</td> <td>   -1.435</td> <td> 0.151</td> <td>   -7.180</td> <td>    1.109</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     CROSS_SELL_SUCCESS   No. Observations:                 1459\n",
       "Model:                          Logit   Df Residuals:                     1442\n",
       "Method:                           MLE   Df Model:                           16\n",
       "Date:                Wed, 05 Feb 2020   Pseudo R-squ.:                  0.4375\n",
       "Time:                        22:58:29   Log-Likelihood:                -515.32\n",
       "converged:                       True   LL-Null:                       -916.19\n",
       "Covariance Type:            nonrobust   LLR p-value:                2.691e-160\n",
       "====================================================================================================\n",
       "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------\n",
       "Intercept                           -1.1058      0.824     -1.342      0.180      -2.720       0.509\n",
       "REVENUE                             -0.0002   9.28e-05     -1.771      0.077      -0.000    1.75e-05\n",
       "MOBILE_NUMBER                        0.8683      0.232      3.744      0.000       0.414       1.323\n",
       "CANCELLATIONS_BEFORE_NOON            0.2472      0.053      4.632      0.000       0.143       0.352\n",
       "CANCELLATIONS_AFTER_NOON            -0.2809      0.175     -1.602      0.109      -0.624       0.063\n",
       "EARLY_DELIVERIES                     0.0628      0.035      1.795      0.073      -0.006       0.131\n",
       "LATE_DELIVERIES                      0.0571      0.029      1.952      0.051      -0.000       0.114\n",
       "FOLLOWED_RECOMMENDATIONS_PCT         0.0451      0.006      7.640      0.000       0.034       0.057\n",
       "AVG_CLICKS_PER_VISIT                -0.1109      0.040     -2.773      0.006      -0.189      -0.033\n",
       "JUNK_DOMAIN                         -1.2095      0.206     -5.863      0.000      -1.614      -0.805\n",
       "PROFESSIONAL_DOMAIN                  0.7882      0.179      4.403      0.000       0.437       1.139\n",
       "NUMBER_NAMES                         0.4757      0.217      2.192      0.028       0.050       0.901\n",
       "SAME_NAME                           -0.9284      0.265     -3.505      0.000      -1.448      -0.409\n",
       "ATTENDED_MASTER_CLASS                0.2648      0.175      1.512      0.131      -0.079       0.608\n",
       "NOBLE                               -1.7068      0.590     -2.893      0.004      -2.863      -0.550\n",
       "out_FOLLOWED_RECOMMENDATIONS_PCT     2.4356      0.219     11.126      0.000       2.007       2.865\n",
       "out_LATE_DELIVERIES                 -3.0353      2.115     -1.435      0.151      -7.180       1.109\n",
       "====================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_fitted_w_out = smf.logit(formula   = \"\"\"CROSS_SELL_SUCCESS ~ \n",
    "REVENUE +\n",
    "MOBILE_NUMBER +\n",
    "CANCELLATIONS_BEFORE_NOON +\n",
    "CANCELLATIONS_AFTER_NOON +\n",
    "EARLY_DELIVERIES +\n",
    "LATE_DELIVERIES +\n",
    "FOLLOWED_RECOMMENDATIONS_PCT +\n",
    "AVG_CLICKS_PER_VISIT +\n",
    "JUNK_DOMAIN +\n",
    "PROFESSIONAL_DOMAIN +\n",
    "NUMBER_NAMES +\n",
    "SAME_NAME +\n",
    "ATTENDED_MASTER_CLASS +\n",
    "NOBLE +\n",
    "out_FOLLOWED_RECOMMENDATIONS_PCT +\n",
    "out_LATE_DELIVERIES \n",
    " \"\"\", data = chef_train)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_fitted_w_out.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Variable dictinary for Signingicant variables and the full dataset\n",
    "\n",
    "variable_dict = {\n",
    "    'logit_sig' : ['REVENUE', 'MOBILE_NUMBER','CANCELLATIONS_BEFORE_NOON',\n",
    "                   'CANCELLATIONS_AFTER_NOON','EARLY_DELIVERIES', 'LATE_DELIVERIES',\n",
    "                   'FOLLOWED_RECOMMENDATIONS_PCT', 'AVG_CLICKS_PER_VISIT',\n",
    "                    'JUNK_DOMAIN', 'PROFESSIONAL_DOMAIN', 'NUMBER_NAMES',\n",
    "                   'SAME_NAME','ATTENDED_MASTER_CLASS', 'out_FOLLOWED_RECOMMENDATIONS_PCT',\n",
    "                   'NOBLE'],\n",
    "    \n",
    "    \n",
    "   'logit_full' : ['REVENUE', 'TOTAL_MEALS_ORDERED',\n",
    "                   'UNIQUE_MEALS_PURCH', 'CONTACTS_W_CUSTOMER_SERVICE', \n",
    "                   'PRODUCT_CATEGORIES_VIEWED', 'AVG_TIME_PER_SITE_VISIT', \n",
    "                   'MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON',\n",
    "                   'CANCELLATIONS_AFTER_NOON', 'TASTES_AND_PREFERENCES',\n",
    "                   'MOBILE_LOGINS', 'PC_LOGINS', 'EARLY_DELIVERIES', \n",
    "                   'LATE_DELIVERIES', 'PACKAGE_LOCKER', 'REFRIGERATED_LOCKER',\n",
    "                   'FOLLOWED_RECOMMENDATIONS_PCT', 'AVG_PREP_VID_TIME', \n",
    "                   'LARGEST_ORDER_SIZE', 'MEDIAN_MEAL_RATING', \n",
    "                   'AVG_CLICKS_PER_VISIT', 'TOTAL_PHOTOS_VIEWED', \n",
    "                   'AVG_PRICE_PER_MEAL', 'JUNK_DOMAIN', 'PROFESSIONAL_DOMAIN', 'NUMBER_NAMES', 'SAME_NAME',\n",
    "                   'NOBLE', 'WEEKLY_PLAN',\n",
    "                   'out_FOLLOWED_RECOMMENDATIONS_PCT', 'out_REVENUE',\n",
    "                   'out_TOTAL_MEALS_ORDERED', 'out_UNIQUE_MEALS_PURCH',\n",
    "                   'out_CONTACTS_W_CUSTOMER_SERVICE', \n",
    "                   'out_AVG_TIME_PER_SITE_VISIT', 'out_CANCELLATIONS_BEFORE_NOON',\n",
    "                   'out_LATE_DELIVERIES', 'out_AVG_PREP_VID_TIME', \n",
    "                   'out_TOTAL_PHOTOS_VIEWED', 'out_AVG_PRICE_PER_MEAL']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development\n",
    "Divided the significant variables into a train and test set\n",
    "\n",
    "Stratify = FOLLOWED_RECOMMENDATIONS_PCT\n",
    "Because it is the most important variables and will help the model if the distribution of variables within is equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into a data and a target dataset\n",
    "original_df_data   =  original_df.loc[ : , variable_dict['logit_sig']]\n",
    "original_df_target =  original_df.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            original_df_data,\n",
    "            original_df_target,\n",
    "            random_state = 222,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = original_df['FOLLOWED_RECOMMENDATIONS_PCT'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide a standardized data set into train and test variable to run models side by side\n",
    "\n",
    "original_df_data   =  original_df.loc[ : , variable_dict['logit_sig']]\n",
    "original_df_target =  original_df.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# FITTING the independent variable data\n",
    "scaler.fit(original_df_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING the independent variable data\n",
    "X_scaled     = scaler.transform(original_df_data)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "X_scaled_df  = pd.DataFrame(X_scaled) \n",
    "\n",
    "\n",
    "# Train test split with all the scaled data\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "                    X_scaled_df,\n",
    "                    original_df_target,\n",
    "                    random_state = 222,\n",
    "                    test_size = 0.25,\n",
    "                    stratify = original_df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list to keep track of model values\n",
    "model_performance = [['Model', 'Training Accuracy',\n",
    "                      'Testing Accuracy', 'AUC Value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8177\n",
      "Testing  ACCURACY: 0.807\n",
      "AUC Score        : 0.7918665636688893\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'liblinear',\n",
    "                                 C = 1,\n",
    "                      random_state = 222)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', logreg_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = logreg_pred))\n",
    "\n",
    "# Adding model results to table\n",
    "model_performance.append(['Logistic Regression w significant var',\n",
    "                          logreg_fit.score(X_train, y_train).round(4),\n",
    "                          logreg_fit.score(X_test, y_test).round(4),\n",
    "                          roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = logreg_pred).round(4)])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.817\n",
      "Testing  ACCURACY: 0.7967\n",
      "AUC Score        : 0.7572526919203655\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'liblinear',\n",
    "                            C = 1,\n",
    "                            random_state = 222)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', logreg_fit.score(X_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(X_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_scaled,\n",
    "                                          y_score = logreg_pred))\n",
    "\n",
    "# Adding model results to table\n",
    "model_performance.append(['Logistic Regression scaled significant var',\n",
    "                          logreg_fit.score(X_train_scaled, y_train_scaled).round(4),\n",
    "                          logreg_fit.score(X_test_scaled, y_test_scaled).round(4),\n",
    "                          roc_auc_score(y_true  = y_test_scaled,\n",
    "                                        y_score = logreg_pred).round(4)])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 1.0\n",
      "Testing  ACCURACY: 0.7577\n",
      "AUC Score        : 0.708\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "tree_pruned      = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "tree_pruned_fit  = tree_pruned.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING test data set\n",
    "tree_pred = tree_pruned_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', tree_pruned_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_pruned_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_pred).round(4))\n",
    "\n",
    "# Adding model results to table\n",
    "model_performance.append(['Decision Tree w significant var',\n",
    "                          tree_pruned_fit.score(X_train, y_train).round(4),\n",
    "                          tree_pruned_fit.score(X_test, y_test).round(4),\n",
    "                          roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_pred).round(4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 1.0\n",
      "Testing  ACCURACY: 0.7372\n",
      "AUC Score        : 0.7016\n"
     ]
    }
   ],
   "source": [
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', full_tree_fit.score(X_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', full_tree_fit.score(X_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_scaled,\n",
    "                                          y_score = full_tree_pred).round(4))\n",
    "\n",
    "# Adding model results to table\n",
    "model_performance.append(['Decision tree scaled w significant var',\n",
    "                          full_tree_fit.score(X_train_scaled, y_train_scaled).round(4),\n",
    "                          full_tree_fit.score(X_test_scaled, y_test_scaled).round(4),\n",
    "                          roc_auc_score(y_true  = y_test_scaled,\n",
    "                                          y_score = full_tree_pred).round(4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.83\n",
      "Testing  ACCURACY: 0.8111\n",
      "AUC Score        : 0.8029\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification \n",
    "g_boost = GradientBoostingClassifier(loss = 'deviance',\n",
    "                                     criterion = 'mae',\n",
    "                                     learning_rate =  0.1,\n",
    "                                     n_estimators = 95,\n",
    "                                     max_features = 3,\n",
    "                                     random_state  = 222)\n",
    "\n",
    "# FITTING the training data\n",
    "g_boost_fit = g_boost.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTING on test data\n",
    "g_boost_pred = g_boost_fit.predict(X_test)\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', g_boost_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', g_boost_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = g_boost_pred).round(4))\n",
    "\n",
    "# Adding model results to table\n",
    "model_performance.append(['GradientBoosting w significant var',\n",
    "                          g_boost_fit.score(X_train, y_train).round(4),\n",
    "                          g_boost_fit.score(X_test, y_test).round(4),\n",
    "                          roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = g_boost_pred).round(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "#loss          = ['deviance', 'exponential']\n",
    "#learning_rate = pd.np.arange(0.1, 0.5, 0.1)\n",
    "#n_estimators  = range(95,105,5)\n",
    "#criterion     = ['friedman_mse', 'mae', 'mse']\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "\n",
    "#param_grid = {'loss'          : loss,\n",
    "#              'learning_rate' : learning_rate,\n",
    "#              'n_estimators'  : n_estimators,\n",
    "#              'criterion'     : criterion}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "\n",
    "#boost_tuned = GradientBoostingClassifier( max_features = 3,\n",
    "#                                         random_state  = 222,\n",
    "#                                               verbose = 1)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "\n",
    "#boost_tuned_grid = GridSearchCV(estimator = boost_tuned,\n",
    "#                               param_grid = param_grid,\n",
    "#                                       cv = 4,\n",
    "#                                  scoring = make_scorer(roc_auc_score,\n",
    "#                                                        needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "\n",
    "#boost_tuned_grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "\n",
    "#print(\"Tuned Parameters  :\", boost_tuned_grid.best_params_)\n",
    "#print(\"Tuned CV AUC      :\", boost_tuned_grid.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8417\n",
      "Testing  ACCURACY: 0.8049\n",
      "AUC Score        : 0.7582\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification \n",
    "g_boost = GradientBoostingClassifier(loss = 'deviance',\n",
    "                                     criterion = 'mae',\n",
    "                                     learning_rate =  0.1,\n",
    "                                     n_estimators = 95,\n",
    "                                     max_features = 3,\n",
    "                                     random_state  = 222)\n",
    "\n",
    "# FITTING the training data\n",
    "g_boost_fit = g_boost.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# PREDICTING on test data\n",
    "g_boost_pred = g_boost_fit.predict(X_test_scaled)\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', g_boost_fit.score(X_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', g_boost_fit.score(X_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_scaled,\n",
    "                                          y_score = g_boost_pred).round(4))\n",
    "\n",
    "# Adding model results to table\n",
    "model_performance.append(['GradientBoosting scaled w significant var',\n",
    "                          g_boost_fit.score(X_train_scaled, y_train_scaled).round(4),\n",
    "                          g_boost_fit.score(X_test_scaled, y_test_scaled).round(4),\n",
    "                          roc_auc_score(y_true  = y_test_scaled,\n",
    "                                          y_score = g_boost_pred).round(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8184\n",
      "Testing  ACCURACY: 0.8131\n",
      "AUC Score        : 0.7676\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "rndfor = RandomForestClassifier(criterion = 'gini',\n",
    "                                bootstrap = True, \n",
    "                                max_depth = 4, \n",
    "                                n_estimators = 200,\n",
    "                                min_samples_leaf = 25, \n",
    "                                random_state = 222)\n",
    "\n",
    "# FITTING the training data\n",
    "rndfor_fit = rndfor.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTING on test data\n",
    "rndfor_pred = rndfor_fit.predict(X_test)\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', rndfor_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rndfor_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rndfor_pred).round(4))\n",
    "\n",
    "model_performance.append(['Random Forrest w significant var',\n",
    "                          rndfor_fit.score(X_train, y_train).round(4),\n",
    "                          rndfor_fit.score(X_test, y_test).round(4),\n",
    "                          roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rndfor_pred).round(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8211\n",
      "Testing  ACCURACY: 0.7947\n",
      "AUC Score        : 0.7337\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "rndfor = RandomForestClassifier(criterion = 'gini',\n",
    "                                bootstrap = True, \n",
    "                                max_depth = 4, \n",
    "                                n_estimators = 200,\n",
    "                                min_samples_leaf = 25, \n",
    "                                random_state = 222)\n",
    "\n",
    "# FITTING the training data\n",
    "rndfor_fit = rndfor.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# PREDICTING on test data\n",
    "rndfor_pred = rndfor_fit.predict(X_test_scaled)\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', rndfor_fit.score(X_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', rndfor_fit.score(X_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_scaled,\n",
    "                                          y_score = rndfor_pred).round(4))\n",
    "\n",
    "model_performance.append(['Random Forrest scaled w significant var',\n",
    "                          rndfor_fit.score(X_train_scaled, y_train_scaled).round(4),\n",
    "                          rndfor_fit.score(X_test_scaled, y_test_scaled).round(4),\n",
    "                          roc_auc_score(y_true  = y_test_scaled,\n",
    "                                          y_score = rndfor_pred).round(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User defined function to find the optimal number of neighbors\n",
    "def optimal_neighbors(X_data,\n",
    "                      y_data,\n",
    "                      pct_test=0.25,\n",
    "                      seed=222,\n",
    "                      response_type='class',\n",
    "                      max_neighbors=50):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "X_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 802\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(X_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is: 9\n",
      "Training ACCURACY: 0.8451\n",
      "Testing  ACCURACY: 0.7823\n",
      "AUC Score        : 0.7535\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = optimal_neighbors(X_train, \n",
    "                                                               y_train))\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(X_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(X_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_scaled,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "model_performance.append(['KNeighbor Scaled w significant var',\n",
    "                          knn_fit.score(X_train_scaled, y_train_scaled).round(4),\n",
    "                          knn_fit.score(X_test_scaled, y_test_scaled).round(4),\n",
    "                          roc_auc_score(y_true  = y_test_scaled,\n",
    "                                          y_score = knn_pred).round(4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is: 9\n",
      "Training ACCURACY: 0.7608\n",
      "Testing  ACCURACY: 0.7166\n",
      "AUC Score        : 0.6707\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = optimal_neighbors(X_train, \n",
    "                                                               y_train))\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "model_performance.append(['KNeighbor w significant var',\n",
    "                          knn_fit.score(X_train, y_train).round(4),\n",
    "                          knn_fit.score(X_test, y_test).round(4),\n",
    "                          roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding in all variables to see the ensemble models can do a better job with all\n",
    "original_df_data   =  original_df[variable_dict['logit_full']]\n",
    "original_df_target =  original_df.loc[:,'CROSS_SELL_SUCCESS']\n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            original_df_data,\n",
    "            original_df_target,\n",
    "            random_state = 222,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = original_df['FOLLOWED_RECOMMENDATIONS_PCT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8218\n",
      "Testing  ACCURACY: 0.8234\n",
      "AUC Score        : 0.7708\n"
     ]
    }
   ],
   "source": [
    "rndfor = RandomForestClassifier(criterion = 'gini',\n",
    "                                bootstrap = True, \n",
    "                                max_depth = 4, \n",
    "                                n_estimators = 200,\n",
    "                                min_samples_leaf = 25, \n",
    "                                random_state = 222)\n",
    "\n",
    "# FITTING the training data\n",
    "rndfor_fit = rndfor.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTING on test data\n",
    "rndfor_pred = rndfor_fit.predict(X_test)\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', rndfor_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rndfor_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rndfor_pred).round(4))\n",
    "\n",
    "model_performance.append(['Random Forrest w all var',\n",
    "                          rndfor_fit.score(X_train, y_train).round(4),\n",
    "                          rndfor_fit.score(X_test, y_test).round(4),\n",
    "                          roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rndfor_pred).round(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is: 34\n",
      "Training ACCURACY: 0.6799\n",
      "Testing  ACCURACY: 0.7125\n",
      "AUC Score        : 0.5411\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = optimal_neighbors(X_train, \n",
    "                                                               y_train))\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "model_performance.append(['KNeighbor w all var',\n",
    "                          knn_fit.score(X_train, y_train).round(4),\n",
    "                          knn_fit.score(X_test, y_test).round(4),\n",
    "                          roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.902\n",
      "Testing  ACCURACY: 0.8049\n",
      "AUC Score        : 0.7843\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification \n",
    "g_boost = GradientBoostingClassifier()\n",
    "\n",
    "# FITTING the training data\n",
    "g_boost_fit = g_boost.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTING on test data\n",
    "g_boost_pred = g_boost_fit.predict(X_test)\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', g_boost_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', g_boost_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = g_boost_pred).round(4))\n",
    "\n",
    "\n",
    "model_performance.append(['GradientBoosting w all var',\n",
    "                          g_boost_fit.score(X_train, y_train).round(4),\n",
    "                          g_boost_fit.score(X_test, y_test).round(4),\n",
    "                          roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = g_boost_pred).round(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             0                  1  \\\n",
      "0                                        Model  Training Accuracy   \n",
      "1        Logistic Regression w significant var             0.8177   \n",
      "2   Logistic Regression scaled significant var              0.817   \n",
      "3              Decision Tree w significant var                  1   \n",
      "4       Decision tree scaled w significant var                  1   \n",
      "5           GradientBoosting w significant var               0.83   \n",
      "6    GradientBoosting scaled w significant var             0.8417   \n",
      "7             Random Forrest w significant var             0.8184   \n",
      "8      Random Forrest scaled w significant var             0.8211   \n",
      "9           KNeighbor Scaled w significant var             0.8451   \n",
      "10                 KNeighbor w significant var             0.7608   \n",
      "11                    Random Forrest w all var             0.8218   \n",
      "12                         KNeighbor w all var             0.6799   \n",
      "13                  GradientBoosting w all var              0.902   \n",
      "\n",
      "                   2          3  \n",
      "0   Testing Accuracy  AUC Value  \n",
      "1              0.807     0.7919  \n",
      "2             0.7967     0.7573  \n",
      "3             0.7577      0.708  \n",
      "4             0.7372     0.7016  \n",
      "5             0.8111     0.8029  \n",
      "6             0.8049     0.7582  \n",
      "7             0.8131     0.7676  \n",
      "8             0.7947     0.7337  \n",
      "9             0.7823     0.7535  \n",
      "10            0.7166     0.6707  \n",
      "11            0.8234     0.7708  \n",
      "12            0.7125     0.5411  \n",
      "13            0.8049     0.7843  \n"
     ]
    }
   ],
   "source": [
    "# The complete list of models and parameters used. I ran and hyperparam tuned other models, but they were not better\n",
    "print(pd.DataFrame(model_performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
