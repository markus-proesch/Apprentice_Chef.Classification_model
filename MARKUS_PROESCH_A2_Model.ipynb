{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student Name : Markus Proesch\n",
    "# Cohort       : 4\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Import Packages\n",
    "################################################################################\n",
    "\n",
    "import pandas as pd                                      # data science essentials\n",
    "import matplotlib.pyplot as plt                          # data visualization\n",
    "import seaborn as sns                                    # enhanced data visualization\n",
    "import statsmodels.formula.api as smf                    # explanatory model \n",
    "from sklearn.model_selection import train_test_split     # divides dataset into a train and test set\n",
    "from sklearn.linear_model import LogisticRegression      # Logistic Regression\n",
    "from sklearn.metrics import confusion_matrix             # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score                # Calculating the ROC and AUC\n",
    "from sklearn.neighbors import KNeighborsClassifier       # KNN for classification\n",
    "from sklearn.preprocessing import StandardScaler         # Standardizing values\n",
    "from sklearn.tree import DecisionTreeClassifier          # classification trees\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # Gradient Booster for classification\n",
    "from sklearn.ensemble import RandomForestClassifier      # Random Forest for classification   \n",
    "from sklearn.model_selection import GridSearchCV         # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer                  # customizable scorer\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Load Data\n",
    "################################################################################\n",
    "\n",
    "\n",
    "original_df     = pd.read_excel('Apprentice Chef Dataset.xlsx')\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Feature Engineering, Variable Selection and (optional) Dataset Standardization\n",
    "################################################################################\n",
    "\n",
    "# Add Avg. Price per Meal variable\n",
    "original_df['AVG_PRICE_PER_MEAL'] = original_df['REVENUE']/original_df['TOTAL_MEALS_ORDERED']\n",
    "\n",
    "\n",
    "# Flagging all observations/customers with no input in FAMILY_NAME\n",
    "for col in original_df:\n",
    "\n",
    "        if original_df[col].isnull().astype(int).sum() > 0:\n",
    "            original_df['mv_'+col] = original_df[col].isnull().astype(int)\n",
    "\n",
    "# Filled NA in FAMILY_NAME with same name as in FIRST_NAME since that seems to be the way to do it\n",
    "original_df['FAMILY_NAME'] = original_df['FAMILY_NAME'].fillna(original_df['FIRST_NAME'])\n",
    "\n",
    "# Drop the flagged missing values in FAMILY_NAME as they are replaced with FIRST_NAME\n",
    "original_df = original_df.drop(columns = 'mv_FAMILY_NAME')            \n",
    "            \n",
    "\n",
    "# Dummie variables from the email domain.\n",
    "# Dataset has to be a DataFrame for .iterrows() to work\n",
    "original_df_email       = pd.DataFrame(original_df['EMAIL'])\n",
    "\n",
    "placeholder_lst  = []\n",
    "\n",
    "for index, col in original_df_email.iterrows():\n",
    "    split_email  = original_df_email.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "email_df         = pd.DataFrame(placeholder_lst)\n",
    "email_df.columns = ['name', 'domain']\n",
    "\n",
    "# Domain groups\n",
    "personal_domain     = ['@gmail.com', '@yahoo.com','@protonmail.com']\n",
    "professional_domain = ['@mmm.com', '@amex.com','@apple.com',\n",
    "                      '@boeing.com','@caterpillar.com',\n",
    "                      '@chevron.com','@cisco.com','@cocacola.com',\n",
    "                      '@disney.com','@dupont.com','@exxon.com',\n",
    "                      '@ge.org','@goldmansacs.com','@homedepot.com',\n",
    "                      '@ibm.com','@intel.com','@jnj.com',\n",
    "                      '@jpmorgan.com','@mcdonalds.com','@merck.com',\n",
    "                      '@microsoft.com','@nike.com','@pfizer.com',\n",
    "                      '@pg.com','@travelers.com','@unitedtech.com',\n",
    "                      '@unitedhealth.com','@verizon.com','@visa.com',\n",
    "                      '@walmart.com']\n",
    "junk_domain         = ['@me.com', '@aol.com', '@hotmail.com', '@live.com',\n",
    "                       '@msn.com','@passport.com']\n",
    "\n",
    "# For loop categorising the different email domains\n",
    "placeholder_lst = []\n",
    "\n",
    "for domain in email_df['domain']:\n",
    "    \n",
    "    if '@' + domain in personal_domain:\n",
    "        placeholder_lst.append('PERSONAL_DOMAIN')\n",
    "    elif '@' + domain in professional_domain:\n",
    "        placeholder_lst.append('PROFESSIONAL_DOMAIN')\n",
    "    else:\n",
    "        placeholder_lst.append('JUNK_DOMAIN')\n",
    "        \n",
    "# make the columns into a series to append it to original dataset        \n",
    "email_df['DOMAIN_GROUP'] = pd.Series(placeholder_lst)\n",
    "\n",
    "# Add the domain categories column to the original dataset \n",
    "original_df['DOMAIN'] = email_df['DOMAIN_GROUP']\n",
    "\n",
    "# Get dummies from the domain variable and drop the original column\n",
    "one_hot_DOMAIN = pd.get_dummies(original_df['DOMAIN'])\n",
    "\n",
    "# Remove the old and add the 3 new dummy variables (as columns)\n",
    "original_df           = original_df.drop('DOMAIN', axis = 1)\n",
    "original_df           = original_df.join([one_hot_DOMAIN])\n",
    "\n",
    "\n",
    "# Adding variable, counting the number of names in NAME column\n",
    "\n",
    "def text_split_feature(col, df, sep=' ', new_col_name=None):\n",
    "    \"\"\"\n",
    "Splits values in a string Series (as part of a DataFrame) and sums the number\n",
    "of resulting items. Automatically appends summed column to original DataFrame.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "col          : column to split\n",
    "df           : DataFrame where column is located\n",
    "sep          : string sequence to split by, default ' '\n",
    "new_col_name : name of new column after summing split, default\n",
    "               'number_of_names'\n",
    "\"\"\"\n",
    "    \n",
    "    original_df[new_col_name] = 0\n",
    "    \n",
    "    \n",
    "    for index, val in original_df.iterrows():\n",
    "        original_df.loc[index, new_col_name] = len(original_df.loc[index, col].split(sep = ' '))\n",
    "        \n",
    "text_split_feature(col = 'NAME', df = original_df, new_col_name = 'NUMBER_NAMES' )\n",
    "\n",
    "# Flagging variable where FIRST NAME is the same as FAMILY NAME\n",
    "placeholder_lst = []\n",
    "\n",
    "for row,col in original_df.iterrows():\n",
    "    if original_df.loc[row,'FIRST_NAME'] == original_df.loc[row,'FAMILY_NAME']:\n",
    "        placeholder_lst.append(1)\n",
    "    else:\n",
    "        placeholder_lst.append(0)\n",
    "\n",
    "# Adding the placeholder to the SAME_NAME column and drop the old column\n",
    "original_df['SAME_NAME'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n",
    "# Making ATTENDED_MASTER_CLASS a binary variable\n",
    "# 1 = attended 1 or more classes, 0 = did not attend a class\n",
    "placeholder_lst = []\n",
    "\n",
    "for row,col in original_df.iterrows():\n",
    "    if original_df.loc[row,'MASTER_CLASSES_ATTENDED'] >= 1:\n",
    "        placeholder_lst.append(1)\n",
    "    else:\n",
    "        placeholder_lst.append(0)\n",
    "\n",
    "# Adding the placeholder to the ATTENDED_MASTER_CLASS column and drop the old column\n",
    "original_df['ATTENDED_MASTER_CLASS'] = pd.Series(placeholder_lst)\n",
    "original_df = original_df.drop(columns = 'MASTER_CLASSES_ATTENDED')\n",
    "\n",
    "\n",
    "# Flagging NOBLE people from the NAME column\n",
    "# 1 = NOBLE, 0 = Not NOBLE\n",
    "placeholder_lst = []\n",
    "\n",
    "for row,pattern in original_df.iterrows():\n",
    "    if ' of ' in original_df.loc[row,'NAME'] or \\\n",
    "    'lord' in original_df.loc[row,'NAME'] or \\\n",
    "    'Lord' in original_df.loc[row,'NAME'] or \\\n",
    "    ' mo ' in original_df.loc[row,'NAME'] or \\\n",
    "    ' zo ' in original_df.loc[row,'NAME'] or \\\n",
    "    ' Mo ' in original_df.loc[row,'NAME'] or \\\n",
    "    'Knight' in original_df.loc[row, 'NAME'] or \\\n",
    "    'knight'in original_df.loc[row, 'NAME']:\n",
    "        placeholder_lst.append(1)\n",
    "    else:\n",
    "        placeholder_lst.append(0)\n",
    "\n",
    "original_df['NOBLE'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n",
    "# Outliers thresholds determined based on the histograms and scatterplots\n",
    "revenue_hi                    = 6500\n",
    "total_meals_hi                = 320\n",
    "unique_meals_hi               = 12\n",
    "contact_w_customer_service_hi = 12\n",
    "avg_time_per_site_hi          = 400\n",
    "cancel_before_noon_hi         = 7\n",
    "late_deliveries_hi            = 15\n",
    "avg_prep_video_hi             = 350\n",
    "total_photoes_hi              = 900\n",
    "avg_meal_price                = 120\n",
    "follow_rec_pct_hi             = 30\n",
    "follow_rec_pct_lo             = 1\n",
    "\n",
    "\n",
    "# FOLLOWED_RECOMMENDATIONS_PCT\n",
    "original_df['out_FOLLOWED_RECOMMENDATIONS_PCT']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_FOLLOWED_RECOMMENDATIONS_PCT'][original_df['FOLLOWED_RECOMMENDATIONS_PCT'] \n",
    "                                                                      > follow_rec_pct_hi]\n",
    "condition_lo = original_df.loc[0:,'out_FOLLOWED_RECOMMENDATIONS_PCT'][original_df['FOLLOWED_RECOMMENDATIONS_PCT'] \n",
    "                                                                      < follow_rec_pct_lo]\n",
    "\n",
    "\n",
    "original_df['out_FOLLOWED_RECOMMENDATIONS_PCT'].replace(to_replace = condition_hi,\n",
    "                                                        value      = 1,\n",
    "                                                        inplace    = True)\n",
    "original_df['out_FOLLOWED_RECOMMENDATIONS_PCT'].replace(to_replace = condition_lo,\n",
    "                                                        value      = 1,\n",
    "                                                        inplace    = True)\n",
    "\n",
    "# REVENUE\n",
    "original_df['out_REVENUE']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_REVENUE'][original_df['REVENUE'] \n",
    "                                                          > revenue_hi]\n",
    "\n",
    "original_df['out_REVENUE'].replace(to_replace = condition_hi,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "# TOTAL_MEALS_ORDERED\n",
    "original_df['out_TOTAL_MEALS_ORDERED']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_TOTAL_MEALS_ORDERED'][original_df['TOTAL_MEALS_ORDERED'] \n",
    "                                                             > total_meals_hi]\n",
    "\n",
    "original_df['out_TOTAL_MEALS_ORDERED'].replace(to_replace = condition_hi,\n",
    "                                               value      = 1,\n",
    "                                               inplace    = True)\n",
    "\n",
    "# UNIQUE_MEALS_PURCH\n",
    "original_df['out_UNIQUE_MEALS_PURCH']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_UNIQUE_MEALS_PURCH'][original_df['UNIQUE_MEALS_PURCH'] \n",
    "                                                            > unique_meals_hi]\n",
    "\n",
    "original_df['out_UNIQUE_MEALS_PURCH'].replace(to_replace = condition_hi,\n",
    "                                              value      = 1,\n",
    "                                              inplace    = True)\n",
    "\n",
    "# CONTACTS_W_CUSTOMER_SERVICE\n",
    "original_df['out_CONTACTS_W_CUSTOMER_SERVICE']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_CONTACTS_W_CUSTOMER_SERVICE'][original_df['CONTACTS_W_CUSTOMER_SERVICE'] \n",
    "                                                                     > contact_w_customer_service_hi]\n",
    "\n",
    "original_df['out_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_hi,\n",
    "                                                       value      = 1,\n",
    "                                                       inplace    = True)\n",
    "\n",
    "# AVG_TIME_PER_SITE_VISIT\n",
    "original_df['out_AVG_TIME_PER_SITE_VISIT']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_AVG_TIME_PER_SITE_VISIT'][original_df['AVG_TIME_PER_SITE_VISIT'] \n",
    "                                                                 > avg_time_per_site_hi]\n",
    "\n",
    "original_df['out_AVG_TIME_PER_SITE_VISIT'].replace(to_replace = condition_hi,\n",
    "                                                   value      = 1,\n",
    "                                                   inplace    = True)\n",
    "\n",
    "# CANCELLATIONS_BEFORE_NOON\n",
    "original_df['out_CANCELLATIONS_BEFORE_NOON']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_CANCELLATIONS_BEFORE_NOON'][original_df['CANCELLATIONS_BEFORE_NOON'] \n",
    "                                                                   > cancel_before_noon_hi]\n",
    "\n",
    "original_df['out_CANCELLATIONS_BEFORE_NOON'].replace(to_replace = condition_hi,\n",
    "                                                     value      = 1,\n",
    "                                                     inplace    = True)\n",
    "\n",
    "# LATE_DELIVERIES\n",
    "original_df['out_LATE_DELIVERIES']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_LATE_DELIVERIES'][original_df['LATE_DELIVERIES'] \n",
    "                                                         > late_deliveries_hi]\n",
    "\n",
    "original_df['out_LATE_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                           value      = 1,\n",
    "                                           inplace    = True)\n",
    "\n",
    "# AVG_PREP_VID_TIME\n",
    "original_df['out_AVG_PREP_VID_TIME']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_AVG_PREP_VID_TIME'][original_df['AVG_PREP_VID_TIME'] \n",
    "                                                          > avg_prep_video_hi]\n",
    "\n",
    "original_df['out_AVG_PREP_VID_TIME'].replace(to_replace = condition_hi,\n",
    "                                             value      = 1,\n",
    "                                             inplace    = True)\n",
    "\n",
    "# TOTAL_PHOTOS_VIEWED\n",
    "original_df['out_TOTAL_PHOTOS_VIEWED']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_TOTAL_PHOTOS_VIEWED'][original_df['TOTAL_PHOTOS_VIEWED'] \n",
    "                                                          > total_photoes_hi]\n",
    "\n",
    "original_df['out_TOTAL_PHOTOS_VIEWED'].replace(to_replace = condition_hi,\n",
    "                                               value      = 1,\n",
    "                                               inplace    = True)\n",
    "\n",
    "# AVG_PRICE_PER_MEAL\n",
    "original_df['out_AVG_PRICE_PER_MEAL']  = 0\n",
    "condition_hi = original_df.loc[0:,'out_AVG_PRICE_PER_MEAL'][original_df['AVG_PRICE_PER_MEAL'] \n",
    "                                                          > avg_meal_price]\n",
    "\n",
    "original_df['out_AVG_PRICE_PER_MEAL'].replace(to_replace = condition_hi,\n",
    "                                              value      = 1,\n",
    "                                              inplace    = True)\n",
    "\n",
    "\n",
    "# Dictinary with significant variables and all available variables \n",
    "variable_dict = {\n",
    "    'logit_sig' : ['REVENUE', 'MOBILE_NUMBER','CANCELLATIONS_BEFORE_NOON',\n",
    "                   'CANCELLATIONS_AFTER_NOON','EARLY_DELIVERIES', 'LATE_DELIVERIES',\n",
    "                   'FOLLOWED_RECOMMENDATIONS_PCT', 'AVG_CLICKS_PER_VISIT',\n",
    "                    'JUNK_DOMAIN', 'PROFESSIONAL_DOMAIN', 'NUMBER_NAMES',\n",
    "                   'SAME_NAME','ATTENDED_MASTER_CLASS', 'out_FOLLOWED_RECOMMENDATIONS_PCT',\n",
    "                   'NOBLE'],\n",
    "    \n",
    "    \n",
    "   'logit_full' : ['REVENUE', 'TOTAL_MEALS_ORDERED',\n",
    "                   'UNIQUE_MEALS_PURCH', 'CONTACTS_W_CUSTOMER_SERVICE', \n",
    "                   'PRODUCT_CATEGORIES_VIEWED', 'AVG_TIME_PER_SITE_VISIT', \n",
    "                   'MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON',\n",
    "                   'CANCELLATIONS_AFTER_NOON', 'TASTES_AND_PREFERENCES',\n",
    "                   'MOBILE_LOGINS', 'PC_LOGINS', 'EARLY_DELIVERIES', \n",
    "                   'LATE_DELIVERIES', 'PACKAGE_LOCKER', 'REFRIGERATED_LOCKER',\n",
    "                   'FOLLOWED_RECOMMENDATIONS_PCT', 'AVG_PREP_VID_TIME', \n",
    "                   'LARGEST_ORDER_SIZE', 'MEDIAN_MEAL_RATING', \n",
    "                   'AVG_CLICKS_PER_VISIT', 'TOTAL_PHOTOS_VIEWED', \n",
    "                   'AVG_PRICE_PER_MEAL', 'JUNK_DOMAIN', 'PROFESSIONAL_DOMAIN', 'NUMBER_NAMES', 'SAME_NAME',\n",
    "                   'NOBLE', 'WEEKLY_PLAN',\n",
    "                   'out_FOLLOWED_RECOMMENDATIONS_PCT', 'out_REVENUE',\n",
    "                   'out_TOTAL_MEALS_ORDERED', 'out_UNIQUE_MEALS_PURCH',\n",
    "                   'out_CONTACTS_W_CUSTOMER_SERVICE', \n",
    "                   'out_AVG_TIME_PER_SITE_VISIT', 'out_CANCELLATIONS_BEFORE_NOON',\n",
    "                   'out_LATE_DELIVERIES', 'out_AVG_PREP_VID_TIME', \n",
    "                   'out_TOTAL_PHOTOS_VIEWED', 'out_AVG_PRICE_PER_MEAL']\n",
    "}\n",
    "\n",
    "################################################################################\n",
    "# Train/Test Split\n",
    "################################################################################\n",
    "\n",
    "# Divide into a data (with significant variables) and a target dataset\n",
    "original_df_data   =  original_df.loc[ : , variable_dict['logit_sig']]\n",
    "original_df_target =  original_df.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "\n",
    "# Divide into train and test dataset and stratify on FOLLOWED_RECOMMENDATIONS_PCT \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            original_df_data,\n",
    "            original_df_target,\n",
    "            random_state = 222,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = original_df['FOLLOWED_RECOMMENDATIONS_PCT'])\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Final Model (instantiate, fit, and predict)\n",
    "################################################################################\n",
    "\n",
    "# INSTANTIATING a classification \n",
    "g_boost = GradientBoostingClassifier(loss = 'deviance',\n",
    "                                     criterion = 'mae',\n",
    "                                     learning_rate =  0.1,\n",
    "                                     n_estimators = 95,\n",
    "                                     max_features = 3,\n",
    "                                     random_state  = 222)\n",
    "\n",
    "# FITTING the training data\n",
    "g_boost_fit = g_boost.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTING on test data\n",
    "g_boost_pred = g_boost_fit.predict(X_test)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Final Model Score (score)\n",
    "################################################################################\n",
    "\n",
    "\n",
    "test_score = roc_auc_score(y_true  = y_test,\n",
    "                           y_score = g_boost_pred).round(4)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
